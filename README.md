# Rscompile

General compiler tools written in Rust for educational purposes.

# Components:
- [x] Tokenizer
- [x] Parser
- [ ] Analyzer
- [ ] Generator

# Tokenizer

Tokenizes a sequence of characters (String) using 2 states recognized using regular expressions:
1. Any number of TOKEN regexes
2. One IGNORE regex

Outputs a Token sequence as a Vector. Token struct contains the original token string slice and also a TokenTypeId representing the Token type. The TokenTypeId corresponds to the index of the Token pattern given to the Tokenizer constructor.

TOKENS may be SINGLE or SURROUND types
1. SINGLE: captures the whole pattern at once
2. SURROUND: finds the begin and end pattern, and capturing them and everything in between, with optional escape characters

General rules are:
1. TOKENS can appear consecutively, or with IGNORE chars in between them. IGNORE chars are discarded.
2. Whitespace is trimmed from start and end of the input string automatically
3. Regex patterns are tried in the order given during the construction of the Tokenizer (IGNORE is always tried last)

An EOF Token is automatically added to the end of the Token sequence. This EOF Token has a TokenTypeId of -1. The TokenTypeIds are also used subsequently in parsing the token sequence.

The given regexes must be able to handle all chars in the input to tokenize successfully (except for inner characters of SURROUND tokens). For well-defined behavior, the IGNORE regex should be defined to consume all chars in between valid tokens.

To do:
> Configure trimming of whitespace


# Parser/Grammar

Table-driven Parser that creates an abstract syntax tree from a sequence of tokens (such as one created by Tokenizer). The grammar rules can be customized prior to parsing by creating a custom Grammar instance. The output is a tree of connected Node objects, each associated to a Grammar Variable Type as defined in the grammar.

Currently only accepts LL(k) unambiguous grammars for any k and LR(1) grammars (LALR).

Grammar is generated by configuring a GrammarGenerator, and calling generate() to return the Grammar. The Grammar should be treated immutable once generated.

GrammarGenerator is configured by creating Gvars (Grammar Variables) of Non-Terminals and Terminals through new_nonterm or new_term, and then creating Productions using make_prod. Non-terminals must have at least 1 production. Terminals need to be given the associated TokenTypeId upon creation.

To parse, the Parser is fed a sequence (Vec) of Tokens produced by Tokenizer. Each Token has its identifying TokenTypeId and the actual string extract from the parsed text.

Note: The parser treats all input tokens as part of the grammar, so if using the token sequence created by Tokenizer, make sure to include the EOF token in the Grammar definition.

## ParserLL

A parser for LL(k) grammars (Left-to-right, leftmost derivation). Can parse LL(k) for any k as long as the grammar is unambiguous and the lookahead does not need to go through a recursion.

Example LL grammar (with common prefix)

Program -> Expression EOF
Expression -> Term Operator Expression
Expression -> Term
Term -> [0-9]+
Operator -> [-+/*]

Common prefixes can be eliminated to minimize k for LL(k). This can be done by the following:

LL grammar eliminating common prefixes

Program -> Expression EOF
Expression -> Term Expression_Tail
Expression_Tail -> Operator Term Expression_Tail
Expression_Tail -> eps
Term -> [0-9]+
Operator -> [-+/*]

The first grammar is LL(2), while the second is LL(1).

## ParserLR

An LALR Parser (SLR(1)) using a parse table to select the proper action based on the current state and the next token.

Example LR grammar

Program -> Expression EOF
Expression -> Expression Operator Term
Expression -> Term
Term -> [0-9]+
Operator -> [-+/*]

To Do:
> Automatic conversion between grammar classes
> Configure resolving of ambiguity
> Descriptive errors
> Implied EOF token


cleanup gvars
cleanup typedefs