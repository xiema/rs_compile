# RISC-V Assembler

A RISC-V Assembler written in Rust for educational purposes.

# Tokenizer

Tokenizes a sequence of characters (String) using 2 states recognized using regular expressions:
1. TOKEN - for recognizing valid tokens
2. IGNORE - for recognizing "whitespace" that must be discarded

Multiple patterns can be used for TOKENS.

Outputs a Token sequence as a Vector. Token struct contains the original token string slice and also a TokenTypeId representing the Token type. The TokenTypeId corresponds to the index of the Token pattern given to the Tokenizer constructor.

An EOF Token is automatically added to the end of the Token sequence. The EOF Token has a TokenTypeId of -1.

The TokenTypeIds are also used subsequently in parsing the token sequence.

General rules are:
1. TOKENS can appear consecutively, or with IGNORE chars and at most one BLANK in between them. IGNORE chars are discarded.
2. Whitespace is trimmed from start and end of the input string automatically

The only valid transitions are:
1. START -> TOKEN, IGNORE
2. TOKEN -> TOKEN, IGNORE
3. IGNORE -> TOKEN

Regex for each category is customizable and defined at creation of the tokenizer. The regex must be able to handle all chars in the input to tokenize successfully.

For well-defined behavior, the ff guidelines should be followed:
1. Regex for TOKENS should not contain any chars from IGNORE or BLANK
2. Regex for IGNORE should not contain any chars from BLANK

To do:
> Recognize surrounds (parentheses, quotes, etc.)
> Ignore comments
> Configure trimming of whitespace


# Parser/Grammar

Table-driven Parser that creates an abstract syntax tree from a sequence of tokens (such as one created by Tokenizer). The grammar rules can be customized prior to parsing by creating a custom Grammar instance.

Currently only accepts LL(1) grammars.

Grammar is generated by configuring a GrammarGenerator which must be mutable, and calling generate() to return the Grammar. The Grammar is unmodifiable once generated.

GrammarGenerator is configured by creating NodeDefs of Non-Terminals and Terminals through new_nonterm or new_term, and then creating Productions using make_prod. Non-terminals must have at least 1 production. Terminals need a Regex pattern that must match any valid token for it.

Note: The parser treats all input tokens as part of the grammar, so if using the token sequence created by Tokenizer, make sure to include the EOF token in the Grammar definition.

Example LL grammar (with common prefix)

Expression -> Term Operator Expression
Expression -> Term
Term -> [0-9]+
Operator -> [-+/*]

Common prefixes must be eliminated for top-down parsing. This can be done by the following:

LL grammar eliminating common prefixes

Expression -> Term Expression_Tail
Expression_Tail -> Operator Term Expression_Tail
Expression_Tail -> eps
Term -> [0-9]+
Operator -> [-+/*]

To Do:
> Automatic conversion between grammar classes